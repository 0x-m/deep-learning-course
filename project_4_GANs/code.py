# -*- coding: utf-8 -*-
"""Untitled20.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fBDOrdUGGOZeI6XoIQ_p98WccVzY2TeA
"""

import numpy as np
import keras
from keras import layers,Model,Input
from keras.datasets import mnist
import tensorflow as tf

#-----------------------discriminator model-----------------------
def get_disc():
  x = Input(shape=(28,28,1)) #
  y = layers.Conv2D(64,(5,5),strides=(2,2),padding='same')(x)
  y = layers.LeakyReLU()(y)
  y = layers.Dropout(rate=0.6)(y)
  y = layers.BatchNormalization()(y)
  y = layers.Conv2D(128,(5,5),strides=(2,2),padding='same')(y)
  y = layers.LeakyReLU()(y)
  y = layers.Dropout(rate=0.6)(y)
  y = layers.BatchNormalization()(y)
  y = layers.Flatten()(y)
  y = layers.Dense(1,activation='sigmoid')(y)

  disc_model = Model(x,y,name='discriminator')
  opt = keras.optimizers.Adam(lr=0.0001,beta_1=0.5)
  disc_model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])
 
  return disc_model
#----------------------------------------------------------------

#--------------------------------generator model-------------------------
def get_gen(noise_dim):
  a = Input(shape=(noise_dim,))
  b = layers.Dense((7*7*256))(a)
  b = layers.Dropout(rate = 0.6)(b)
  b = layers.LeakyReLU()(b)
  
  b = layers.BatchNormalization()(b)
 
  b = layers.Reshape((7,7,256))(b)

  b = layers.Conv2DTranspose(128,(5,5),strides=(1,1),padding='same',use_bias=False)(b)
  b = layers.BatchNormalization()(b)
  b = layers.Dropout(rate = 0.6)(b)
  b = layers.LeakyReLU()(b)
 

  b = layers.Conv2DTranspose(128,(5,5),strides=(2,2),padding='same',use_bias=False)(b)
  b = layers.BatchNormalization()(b)
  b = layers.Dropout(rate = 0.6)(b)
  b = layers.LeakyReLU()(b)

  b = layers.Conv2DTranspose(128,(5,5),strides=(1,1),padding='same',use_bias=False)(b)
  b = layers.BatchNormalization()(b)
  b = layers.Dropout(rate = 0.6)(b)
  b = layers.LeakyReLU()(b)

  b = layers.Conv2DTranspose(1,(7,7),strides=(2,2),padding='same',activation='tanh',use_bias=False)(b)

  gen_model = Model(a,b,name='generator')
  return gen_model
#------------------------------------------------------------------------

#aux functions----------------------
def get_true_batch(train_data,n_samples):
  i = np.random.randint(0,train_data.shape[0],n_samples)
  samples = train_data[i]
  labels = np.ones((n_samples,1))
  return samples,labels

def get_fake_batch(g_model,n_samples,noise_dim):
  noise = np.random.uniform(-1,1,(n_samples,noise_dim))
  samples = g_model.predict(noise)
  labels = np.zeros((n_samples,1))
  return samples,labels
  
def get_noise(noise_dim,batch_size):
  noise = np.random.uniform(-1,1,(batch_size,noise_dim))
  labels = np.ones((batch_size,1))
  return noise,labels

#--------------------GAN model------------------------------
def get_gan(g_model,d_model):
  inp = Input(shape=(noise_dim,))
  out = g_model(inp)
  out = d_model(out)
  gan_model = Model(inp,out,name='gan')
  opt = keras.optimizers.Adam(lr=0.0204,beta_1=0.5)
  d_model.trainable = False;
  gan_model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])
  return gan_model
#----------------------------------------------------------



#-------------train GAN--------------
def train(train_data,g_model,d_model,gan_model,noise_dim,epochs,batch_size):
  n_batch = int(train_data.shape[0]/batch_size)
  for epoch in range(epochs):
    for batch in range(n_batch):
     x_r,y_r = get_true_batch(train_data,batch_size)
     x_f,y_f = get_fake_batch(g_model,batch_size,noise_dim)

     y_r = np.ones((batch_size,1))
     r_loss = d_model.train_on_batch(x_r,y_r)
     f_loss = d_model.train_on_batch(x_f,y_f)
     noise,lbl = get_noise(noise_dim,batch_size)
     gan_loss = gan_model.train_on_batch(noise,lbl)
  print('epoch: ' + str(epoch+1))
#----------------------------------------

#load data-----------------------------------------------------------
(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data();
x_train = x_train.reshape(x_train.shape[0],28,28,1).astype('float32')
x_train = x_train / 255 #normalize to [0,1]

noise_dim = 100
#--------------------------------------------
disc_model = get_disc()
gen_model = get_gen(noise_dim)
gan_model = get_gan(gen_model,disc_model)
#--------------------------------------------

disc_model.summary()

train(x_train,gen_model,disc_model,gan_model,noise_dim,10,2048)

import matplotlib.pyplot as plt
for i in range(16):
  n = np.random.uniform(0,1,(64,noise_dim))
  r = gen_model.predict(n)
  plt.figure()
  for j in range(64):
    plt.subplot(8,8,j+1)
    plt.imshow(h[j,:,:,0],cmap='gray')
    plt.axis('off')

gen_model.summary()

train_discriminator(x_train,10,256,gen_model,disc_model)

tt = x_train[:10,:,:,0].reshape(10,28,28,1)
hj = disc_model.predict(tt)
print(hj)



gan_model.summary()