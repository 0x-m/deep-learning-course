# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kXrm-sdcj8f_JLBJ7YnJ8ZPBW9W5SLAN
"""

#-------------------Deep learning miniproject 2---------------------------
#author : hamze ghaedi----------------------------------------------------
#--------------------------------------------------------------------------

#----------------------------IMPORTS---------------------------------------
import numpy as np
from tensorflow import keras
import matplotlib.pyplot as plt
import matplotlib.image as pimg
from skimage import color

from keras.datasets import cifar10
(x_train,y_train),(x_test,y_test) = cifar10.load_data()
x_train = x_train / 255
x_test = x_test / 255

def dechromize(x):
  y = np.zeros((len(x),32,32))
  for i in range(0,len(x)):
    y[i] = color.rgb2gray(x[i])
  return y

print(x_train.shape)
x_train = dechromize(x_train)
x_test = dechromize(x_test)

x_train.shape = (50000,32,32,1)
x_test.shape = (10000,32,32,1)
#-------------------normalization----------------------
mean = np.mean(x_train,axis=(0,1,2,3))
std = np.std(x_train,axis=(0,1,2,3))
x_train = (x_train-mean)/(std+1e-7)
x_test = (x_test-mean)/(std+1e-7)
#------------------------------------------------------

x_val = x_train[:5000]
y_val = y_train[:5000]

x_train = x_train[5000:]
y_train = y_train[5000:]



#----------------------Convolutional network------------------------------
CNN_model = keras.models.Sequential([
                                 
                                 keras.layers.Conv2D(32,(3,3),input_shape=(32,32,1),activation='elu',padding='same',kernel_regularizer=
                                                     keras.regularizers.l2(l=0.0001)),
                                 keras.layers.BatchNormalization(),    
                                 keras.layers.Conv2D(32,(3,3),activation='elu',padding='same',kernel_regularizer=
                                                     keras.regularizers.l2(l=0.00001)),
                                 keras.layers.BatchNormalization(), 
                                 keras.layers.MaxPooling2D((2,2)),
                                 keras.layers.Dropout(rate=0.2),
                                 keras.layers.Conv2D(64,(3,3),activation='elu',padding='same',kernel_regularizer=
                                                     keras.regularizers.l2(l=0.00001)),
                                 keras.layers.BatchNormalization(),    
                                 keras.layers.Conv2D(64,(3,3),activation='elu',padding='same',kernel_regularizer=
                                                     keras.regularizers.l2(l=0.00001)),
                                 keras.layers.BatchNormalization(), 
                                 keras.layers.MaxPooling2D((2,2)),
                                 keras.layers.Dropout(rate=0.3),

                                 keras.layers.Flatten(),
                                 keras.layers.Dense(256,activation='elu'),                                      
                                 keras.layers.Dense(10,activation='elu')
])

#--------------------------------------------------------------------------
cb = keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=0.001,patience=5)
CNN_model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)
,loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])
CNN_model.fit(x_train,y_train,batch_size = 32,epochs = 50,validation_data = (x_val,y_val),callbacks=[cb])

#--------------------------------------------------------------------------

#-------------------------Feedforward network------------------------------

FFN_model = keras.models.Sequential([
                                     
                                     keras.layers.Flatten(input_shape=(32,32,1)),
                                     keras.layers.Dense(256,activation='elu',kernel_regularizer=keras.regularizers.l2(0.001)), 
                                     keras.layers.BatchNormalization(),
                                     keras.layers.Dropout(rate = 0.5),
                                     keras.layers.Dense(64,activation='elu',kernel_regularizer=keras.regularizers.l2(0.001)),                                       
                                     keras.layers.Dense(10,activation='elu')
])
cb = keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=0.001,patience=10)
FFN_model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])
FFN_model.fit(x_train,y_train,batch_size = 64,epochs = 100,validation_data = (x_val,y_val),callbacks=[cb])

import matplotlib.pyplot as plt
def visualize(hist):
  plt.figure()
  plt.plot(hist.history['accuracy'])
  plt.plot(hist.history['val_accuracy'])
  plt.title('Accuracy')
  plt.xlabel("epochs")
  plt.ylabel("accuracy")
  plt.legend(['Train', 'Test'], loc='lower right')
  plt.show()
  plt.figure()
  plt.plot(hist.history['loss'])
  plt.plot(hist.history['val_loss'])
  plt.title('Loss')
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Test'], loc='lower right')
  plt.show()

from IPython.display import SVG

keras.utils.plot_model(FFN_model,to_file='ffn.png')

from IPython.display import SVG

keras.utils.plot_model(CNN_model,to_file='ffn.png')

visualize(FFN_model.history)

visualize(CNN_model.history)

cnn_pred = CNN_model.predict(x_test)

tl = np.zeros(10)
for i in range(0,10000):
  tl[y_test[i]] = tl[y_test[i]] +1

tl = tl / 10000

#--------------predicted distribution for CNN---------------
pl = np.zeros(10)
for i in range(0,10000):
  predicted_label = np.argmax(cnn_pred[i])
  true_label = y_test[i]
  if(predicted_label == true_label):
    pl[true_label] = pl[true_label] + 1
pl = pl / 10000

x = np.arange(10)
p1 = plt.subplot(1,1,1)

b1 = p1.bar(np.arange(10)-0.2,pl,width=0.2,color='b')
b2 = p1.bar(np.arange(10),tl,width=0.2,color='g')
p1.legend([b1,b2],['Predicted','True'],loc='upper left')
plt.title("Predicted vs True Labels Distribution")

CNN_model.evaluate(x_test,y_test)

FFN_model.evaluate(x_test,y_test)

#--------------predicted distribution for FFN---------------
ffn_pred = FFN_model.predict(x_test)
pl = np.zeros(10)
for i in range(0,10000):
  predicted_label = np.argmax(ffn_pred[i])
  true_label = y_test[i]
  if(predicted_label == true_label):
    pl[true_label] = pl[true_label] + 1
pl = pl / 10000

x = np.arange(10)
p2 = plt.subplot(1,1,1)

b2 = p2.bar(np.arange(10)-0.2,pl,width=0.2,color='b')
b3 = p2.bar(np.arange(10),tl,width=0.2,color='g')
p1.legend([b2,b3],['Predicted','True'],loc='upper left')
plt.title("Predicted vs True Labels Distribution")